{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should be run in order to execute the predictions. It will ask for an input. \n",
    "# Also, a name for the output file with the predictions should be given. It will be stored in the same folder as the\n",
    "# tool itself and the datasets. The accuracy and error measurement of both prediction models for event and time \n",
    "# can be found in the poster.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mode\n",
    "import operator\n",
    "import functools\n",
    "import datetime \n",
    "import numpy as np\n",
    "import collections, itertools\n",
    "\n",
    "def process_data():\n",
    "    # Read input\n",
    "    dataset = input(\"Please enter the path of the CSV file: \")\n",
    "    output_name = input(\"Please enter the name (and path) of the output file: \")\n",
    "    df = pd.read_csv(dataset)\n",
    "    \n",
    "    #preprocessing\n",
    "    trace_list = [] # list of traces\n",
    "\n",
    "    for name, group in df.groupby([\"case concept:name\"]):\n",
    "        trace_list.append(group['case concept:name'].tolist())\n",
    "\n",
    "    #define the function#\n",
    "    def find_list_features(list):\n",
    "        list_len = [len(i) for i in list]\n",
    "        return list_len\n",
    "\n",
    "    features = find_list_features(trace_list)\n",
    "\n",
    "    # Setting the limit for extreme traces\n",
    "    limit = np.percentile(features, 95)\n",
    "\n",
    "\n",
    "    # Calculating frequency of each trace\n",
    "    freq = collections.defaultdict(int)  # 0 by default\n",
    "    for x in itertools.chain.from_iterable(trace_list):\n",
    "        freq[x] += 1\n",
    "\n",
    "    # Filtering the frequency dictionary\n",
    "    filtered_dict = {k:v for k,v in freq.items() if v < limit}\n",
    "\n",
    "    # Making a list out of the keys\n",
    "    allowed_traces = [*filtered_dict]\n",
    "\n",
    "    df = df[df['case concept:name'].isin(allowed_traces)]\n",
    "\n",
    "    # Parse the timestamp and convert it into y-m-d form\n",
    "    df['event time:timestamp'] = pd.to_datetime(df['event time:timestamp'], format = '%d-%m-%Y %H:%M:%S.%f')\n",
    "\n",
    "    # Sort data by timestamp in ascending order\n",
    "    df.sort_values(['event time:timestamp'], axis=0, inplace=True)\n",
    "    \n",
    "    # split into train set and test set (80/20)\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, shuffle = False)\n",
    "    \n",
    "    # remove cases started in the training set\n",
    "    df_test = df_test[df_test['case concept:name'].isin(df_train['case concept:name'].values)]\n",
    "\n",
    "    # Reset index\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return (df_train, df_test, output_name)\n",
    "\n",
    "# Functions for event and time prediction, either in one def like last time or split \n",
    "\n",
    "def prediction(df_train, df_test):\n",
    "    # Event prediction\n",
    "    df_sort = df_train.set_index(df_train.groupby('case concept:name').cumcount(), append = True)\n",
    "\n",
    "    df_sort['day of the week'] = df_sort['event time:timestamp'].dt.dayofweek\n",
    "\n",
    "    # Finding the most common event per day of the week\n",
    "    l = len(df_sort['event concept:name'])\n",
    "    lst = []\n",
    "    commonEventPerDay = []\n",
    "    dayList = df_sort['day of the week'].tolist()\n",
    "    eventList = df_sort['event concept:name'].tolist()\n",
    "\n",
    "    for j in range (0, 7):\n",
    "        for i in range (0, l):\n",
    "            if dayList[i] == j:\n",
    "                lst.append(eventList[i])\n",
    "        findMode = mode(lst)\n",
    "        commonEventPerDay.append(findMode)\n",
    "        list = []\n",
    "    \n",
    "    # Time prediction\n",
    "    # Assign position number to each event\n",
    "    df_train = df_train.set_index(df_train.groupby('case concept:name').cumcount(), append = True)\n",
    "    df_test = df_test.set_index(df_test.groupby('case concept:name').cumcount(), append = True)\n",
    "    \n",
    "    #calculate time since started for each case\n",
    "    df_train = df_train.assign(time_since_started=df_train.groupby('case concept:name')['event time:timestamp'].apply(lambda x: x - x.iloc[0]))\n",
    "    \n",
    "    #groupby case concept and calculate average for each position\n",
    "    avg_timespan = df_train.groupby(level=1)['time_since_started'].apply(\n",
    "        lambda x: x.astype('timedelta64[s]').mean()\n",
    "    )\n",
    "\n",
    "    # apply on test set\n",
    "    result = df_test.merge(avg_timespan, left_on = df_test.index.get_level_values(1).values, right_index = True, how = 'left')\n",
    "    \n",
    "    result['time_since_started']=result['time_since_started'].astype('timedelta64[s]')\n",
    "    result['time_prediction']= result.groupby('case concept:name')['event time:timestamp'].transform(lambda x: x.min())+ result['time_since_started']\n",
    "    \n",
    "    # Getting week of the day in test set\n",
    "    result['day of the week'] = result['event time:timestamp'].dt.dayofweek\n",
    "    \n",
    "    \n",
    "    # Making sure that no values are above 6 since we consider 0,...,6 as days of the week\n",
    "    result['day of the week'] = np.where(result['day of the week'] > 6, result['day of the week'] - 6, result['day of the week'])\n",
    "\n",
    "\n",
    "    # Predicted Event = Most Common Event for that Day of the Week\n",
    "    result['event_prediction'] = result['day of the week']\n",
    "    for i in range (0, 7):\n",
    "        result.loc[result['day of the week'] == i, 'event_prediction'] = commonEventPerDay[i]\n",
    "\n",
    "    result = result.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def save_results(output_name):\n",
    "    result.to_csv(output_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, output_name = process_data()\n",
    "result = prediction(df_train, df_test)\n",
    "save_results(output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
